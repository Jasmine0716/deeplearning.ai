

## 序列模型

##### 循环序列模型

###### one-hot表示法

* 对需要的所有n个单词进行排序，然后每个单词对应一个(1,n)的向量，如第一个单词为(1,0,0,...) 第二个单词为(0,1,0,...)
* 对于不在词表中的单词用特殊方法处理，如用\<UNK>标记



###### 结构

* 多对多结构

  * 输入和输出数量相同

    * 应用：如给定的句子，判断其中的人名。  n个单词的句子&rarr;n个向量&rarr;对每一个输入的向量都进行判断是否是名字，输出n个判断结果

    * 前向传播

      * ![多对多-相同](http://www.ai-start.com/dl2017/images/19cbb2d356a2a6e0f35aa2a946b23a2a.png)

      * 注意，先计算激活值a<sup>\<t></sup>，再计算输出y<sup>\<t></sup>

      * 可以对计算进行变换：

        * W<sub>aa</sub>和W<sub>ax</sub>合并，a<sup>\<t-1></sup>和x<sup>\<t></sup>合并，即
          $$
          W_a=[W_{aa}~~W_{ax}]\\
          a^{<t>}=g(W_a\left[\begin{matrix}a^{<t-1>}\\x^{<t>}\end{matrix}\right]+b_a)
          $$
          

    * 反向传播

      * 损失函数
        $$
        L^{<t>}(\hat{y}^{<t>},y^{<t>})由输出的内容决定，如标准逻辑回归的损失函数-交叉熵损失函数\\
        L(\hat{y}^{<t>},y^{<t>})=\sum^{T_x}_{t=1}L^{<t>}(\hat{y}^{<t>},y^{<t>})
        $$
        

      * 穿越时间的反向传播：对于每一个输出y对应的损失函数，都向前传递，然后将同一个位置的所有梯度都加起来

        ![backpropagate](http://www.ai-start.com/dl2017/images/rnn_cell_backprop.png)

  * 输入和输出不同

    * 应用例子：智能翻译，如英文翻译成中文，可能输入的词的数量和输出的词的数量不同

    * 结构：encoder+decoder

      ![many-many](http://www.ai-start.com/dl2017/images/db580f1dfd6095d672fc62cce74ce5e2.png)如编号2的图像

    * 先进行输入(encoder)，对于输入进行理解，然后进行输入(decoder)

* 一对多结构

  * 应用例子：如音乐合成
  * 如上图的编号1

* 多对一结构

  * 应用例子：根据语言评价输出评分

  * ![many-one](http://www.ai-start.com/dl2017/images/14e1df0a7a8cdd1584b2e92e87e23aa7.png)

    如编号2

* 一对一结构

  * 如上图编号3



##### 语言模型

* 结构和流程
  * 对于一个词库的词用one-hot表示法
  * 将a<sup>\<0></sup>和x<sup>\<0></sup>全部设为0向量，然后用RNN进行逐步预测判断
  * 每一步输入的x<sup>\<t></sup>是外来输入的<mark>正确</mark>的词语
  * 每一步输出的是每个词语的概率
  * 注意：结束标志一般用EOS标记，未知词一般用UNK标记。
* 训练
  * 对于每一步的输出，根据其对应位置的真实应该是的值，计算代价函数，反向传播训练
* 输出理解
  * 由于输出的是概率，则对于一个3个词语的句子，每个对应的概率相乘即是得到整个句子的概率

* 新序列采样
  * 意义
    * 了解模型到底学习到了什么——让模型完全自己输出，看输出了什么
  * 流程
    * 通过random.choice来对于每个输出（词典里面的不同词语对应的概率）进行采样（词语的采样）
    * 让采样得到的y（最大概率的词语）作为下一个x（不用外界进行输入，即one-many）不断传递
    * 结束判断：直到得到EOS/设定特定的时间步长
    * 注意：对于输出位置标志的处理方法，忽略/重新采样，直到得到的不是未知标志
* 基于词汇的RNN模型和基于字符的RNN模型
  * 基于字符：训练时间长，代价大，字符先后的影响关系难以捕捉，长度过长
  * 一般用基于词汇的方法
* 



