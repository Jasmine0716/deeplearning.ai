# 改善深层神经网络  

## 神经网络的参数调整  

* 参数种类  
    * 网络层数  
    * 每层的隐藏单元数  
    * 学习速率  
    * 每层激活函数的选择  

## 数据划分  

* 种类  
    * 训练集  
    * 验证集  
        * 评估哪一种算法更加有效  
    * 测试集  
        * 评估分类器的性能  
        * 最后使用的一个集合  
        * 可以省略，用于无偏估计  
* 比例  
    * 小数据集  
        * 70%训练集+30%测试集  
        * 60%训练集+20%验证集+20%测试集  
    * 大数据集  
        * 测试集和验证集的比例减小，但是验证集的比例需要足够大，训练集的占比可以小一点  
* 选择  
    * 训练集、验证集、测试集的来源和分布最好相同（如清晰度分布大致相同—不一定是要清晰度相同）  

## 方差与偏差  

* 方差（bias）  
    * 衡量拟合的程度，是否过拟合  
    * 当训练集正确率和验证集正确率相差大时->方差大，过拟合  
* 偏差（Variance）  
    * 衡量训练结果相对最优误差/贝叶斯误差（如人眼分类的结果）相差的大小，及训练结果的优良  
    * 当训练结果（训练集误差）差时->偏差大，欠拟合  
* 改进与提升  
    * 偏差  
        * 使用更大的网络  
        * 增加隐藏层的神经元数量  
        * 使用优化算法  
        * 延长训练时间  
    * 方差  
        * 增加数据集数量  
        * 无法增加数据集数量时->增加正则项  
    * 注意：在调整其中一方的时候，可能另外一方也会发生变化->重新得到结果观察变化（也有只影响一方的方法，如增加正则项）  

## 防止过拟合  

* 正则项  
    * 意义  
        * lambd的大小->影响拟合程度  
            * 过小->过拟合  
            * 合适->正常拟合  
            * 过大->欠拟合  
        * 可以防止过拟合  
            * 当lambd取较大值->w较小->每层得到的激活值较小，基本在tanh函数的线性区域->激活函数基本失效->整个网络几乎成为线性，多层失效  
    * 方法  
        * L1正则化  
            * 乘以lambd/m（训练集数量）  
            * 导致w将会变得稀疏（很多为0）  
                * 有利于压缩网络？？有这种说法  
        * L2正则化  
            * 乘以lambd/2m  
            * 经常使用  
        * dropout正则化  
            * 每个神经元的保留概率为p，对于每个训练对象保留的神经网络不相同（需要重新依照概率进行生成）  
            * 目的：加深网络，压缩网络<mark>？？？</mark>  
            * 理解：如何防止过拟合  
                * 起到和L2正则化相似的作用  
                * 由于每一个输入都有可能被清除，所以权重不会聚集分布，更倾向于较为均匀的分布到所有输入上  
                * p-类似于lambd  
                    * 小一点->lambd大一点，加强防止过拟合  
                    * 大一点->lambd小一点，减弱防止过拟合（p=1，没有用dropout）  
                    * p可以变化，根据每一层的具体情况，如没有过拟合危险->p可以大一点；如果参数较多->p可以小一点  
                      
                        * 如：
                        
                            ![](.\img\神经网络.png)
            * 方法  
                * inverted dropout反向随机失活  
                    * 生成随机矩阵(n,m),其中n为此层的神经元的数量，m为样本数量  
                    * 判断矩阵是否小于p  
                    * 对于此层计算出的输出值/激活值矩阵要乘以前面得到的布偶矩阵  
                    * <mark>由于每层的输入有概率1-p不为0，所以为了不改变最终期望值，将z=wa+b变为z=wa/p+b</mark>  
                    * 测试集中<mark>不用考虑概率，正常进行传递</mark>（训练集传递中a/p已经使得概率不发生改变）  
                    * <mark>自己重新实现！！！再理解</mark>  
            * 缺点：<mark>损失函数怎么算？</mark>  
* 其他方法  
    * 增加数据集  
        * 直接增加  
            * 代价消耗大  
        * 间接增加  
            数据扩增data augmentation  
      * 通过已有图像的变化来成新的图像数据（<mark>注意，生成的图片也要能够辨别才有效</mark>）  
                * 反转  
                * 拆建  
                * 角度调整等  
    * early stopping  
        * 原理：不考虑正则化时，随着训练集loss在迭代中逐渐减小时，测试集的loss在迭代中先减小后增大  
          
            ![1597016681651](./img/learning.png)
        * 将中间的地点作为最优点停止迭代
        * 优点  
          
            * 不用调整lambd，不引入超参数  

## 超参数的调试  

* 经验：来自吴恩达老师的经验与直觉，也是一般的常规处理方法  
    * 参数重要程度：  
        * 第一—学习率  
        * 第二—Momentum的beta、隐藏的神经元数量、mini-batch的大小  
        * 第三—隐藏层的数量、学习率的衰减率  
        * adam/RMSprop中的beta1、beta2、最小常亮一般不用调整  
* 选择  
    * 在参数组成的网格点内随机选择  
    * 根据不同的参数情况进行相应的划分，不用均匀划分  
        * 比如学习率 10^(random)  
        * beta: 1-10^(random) 可以通过计算对应平均的以往数值的多少来判断（1/(1-beta)）  
    * 由大范围筛选，逐渐缩小范围，细化划分  
* 训练方式  
    * 当CPU/GPU小：一个模型，逐步调整  
    * 当CPU/GPU足够大：多个模型同时训练，选择最佳  

## Softmax回归/分类器  

* 基本思想：将logistc回归分类的分为两类拓展为分为多个类别，输出每个类别的概率，C=2时和logistic等价  
* 计算  
  
    * 先计算e的幂值，再归一化计算每个概率（总概率为1）  
* 直观感受  
    * 对于没有隐藏层的网络  
        * softmax分类器，将区域分为多个类，每个类之间分界面呈现线性  
        * logistic分类器，将区域进行线性划分，分为两个类  
* hardmax  
  
    * 在logistc分类的基础上将输出变为多个，然后取值最大的类为1，其他为0  
* loss function  
    * 理解：梯度下降等效于使正确类别的概率最大化  
    
      ![loss-w10](./img/loss.png)

## 权重  

* 网络权重的初始化  
    * 对于z=w1x1+...+wnxn，为了防止n过大/小导致z过大/小(<mark>避免不均匀分布？</mark>)  
        * w=random/n(n为输入的数据个数，即上一层神经元的数量)  
        * 对于ReLU一般使用w=random/2n或<mark>w=random/sqrt(2n)(一般更加常用)</mark>  
        * 对于tanh一般使用<mark>w=random/sqrt(n)(更常用)</mark>或w=random*sqrt(2/n[l-1]+n[l])Xavier初始化  

## 反向传播  

* 梯度  
    * 梯度爆炸/消失  
      
        * 理解：比如将网络简单化，变为线性传递后，如果所有的w都大于1->将会导致指数型爆炸增长；当所有的w都小于1->将会导致指数型减小  
    * 梯度验证  
        * 用数值计算的结果和理论计算的梯度结果进行比对  
            * 数值计算  
              
                * 使用双边误差  
                
                  ![数值求导](./img/数值求导.png)
            * 对比  
              
                ![compare](./img/compare.png)
        * 注意事项  
            * 训练是不要进行梯度验证（速度慢），进行单独的梯度验证  
            * 判断是否正确  
                * 小于10^-7 -> 结果较好，基本正确  
                * 10^-5 ~ 10^-7 -> 可能存在错误  
                * 10^-3 -> 很可能有错  
            * 对于有错/可能有错的处理  
              * 对于每个元素依次循环判断，看看是否是其中某些值的误差较大  
          * 不要使用dropout/p设置为1  
          * 小概率情况：梯度验证正确只在初始化w很小的时候正确，在训练中w逐渐增长后不正确  
              * 在开始初始化的时候验证一次；  
                  结束训练时验证一次  
  
* mini-batch梯度下降  
    * 适用条件：训练集过大（2000以下可以直接用batch梯度下降）  
    * 基本思想：为了解决训练对象数量过多导致矩阵过大，计算过大所带来的问题，将训练集划分成多个小块来依次进行迭代训练  
        * <mark>问题：每一个batch单独归一化还是整体一起归一化？</mark>  
    * 特点  
        * loss整体呈现下降趋势，但每一步之间的上升下降在不断波动，batch越小波动越大  
        * 训练更快（选择合适的batch大小时）  
    * batch大小的选择  
        * 影响  
            * m：即变为batch梯度下降，loss单调下降不会波动  
            * 1:随机梯度下降，loss波动过大，最终在最小点附近徘徊，但是失去了向量化带来的优点，训练效率低  
            * 合适：有较好的效果  
        * 选择  
            * 一般选择64-512，且为2的次方（根据计算机的原理）  
            * 要根据CPU/GPU的内存情况选择  
            * 不断尝试调整  
        * <mark>注意：batch size越小 -> 上下摆动越厉害 -> 学习率需要越小</mark>  

## 优化  

* 归一化输入  
    * 方法：使得输入数据集的各个维度数据的分布相似（方差和均值相同）  
        * 先减去均值，再计算方差，除以标准差  
    * 意义  
        * 更容易、更快优化减小损失  
            * ![normalize](./img/norm.png)
            * 当均值和方差相差较大时，J与w的函数呈现狭长形  
            * <mark>没看懂原理</mark>  
* 动量梯度下降法Momentum  
    * 基础知识：指数加权平均值  
        * 计算(如果没有v(0)则需要假定)：v(t)=beta*v(t-1)+(1-beta)*theta(t)  
        * 理解  
            * 在计算当下的平均值时考虑过去值的影响  
            * 过去的影响权重呈现(1-beta)的幂函数变化<mark>（所以叫做指数加权）</mark>，越早影响越小  
            * 大约考虑了过去1/(1-beta)个值的影响：原因-(beta)^(1/(1-beta))约等于1/e，即0.34，影响已经较小，可以忽略  
        * beta的选择  
            * 过大：过去的权重较大，平滑，但延迟大  
            * 过小：过去的权重小，波动较大，但延迟小  
            * 0.9一般是一个较好的选择  
        * 改进：指数加权平均的偏差修正  
            * 原因：单纯使用指数加权平均时，如果beta选择较大，而v0定义为0，则在开始的几个值都会存在过小的情况  
            * 改进计算方法：在每一次计算完v(t)后，修正为v(t)/(1-beta^t)<mark>(可以理解为除去了v0的影响，只使用了其他值的加权平均-1-beta^t即是其他值的权重之和)</mark>  
    * 方法实现  
        * ![momentum](./img/momentum.png)
        * 或者取消1-beta，变为v(t)= beta*v(t-1)+dW/b  
            * <mark>为什么吴恩达老师说这种方法在改变beta时也要调整a？两种更新公式有什么不同？</mark>  
    * 意义  
        * 减小更新时的上下波动，加快训练  
    * 理解  
        * 角度一：从指数加权平均值理解  
        * 角度二：从山上下落时的速度和加速度角度理解  
    * <mark>一般不使用偏差修正</mark>  
        * 为什么？？  
* RMSprop  
    * ![RMSprop](./img/RMSprop.png)
        * <mark>注意:为了防止分母过小/为0，一般在分母（不是根号内部）加一个较小的常量（一般选择10^-8）</mark>  
    * 基本思想：为了防止竖直方向摆动速度过大，水平反向移动速度过小，在速度对应的梯度下除以一个可以体现其大小的量来防止过大/过小。  
    * 学习率可以稍微取大一点的值  
* Adam  
    * ![Adam](./img/Adam.png)
      
        * 参数选择  
        
          ![hyparameters](./img/hyparameters.png)
    * 基本思想：结合momentum算法和RMSprop算法（RMSprop可以看作是momentum的修正）  
* 学习率衰减  
    * 基本思想：由于使用mini-batch训练，梯度并不只是指向最低点的，在不断学习中，靠近最值点后为了防止由于方向的不准确带来的误差过大，将减小学习率来改善  
    * 衰减方法  
        * a = (1/(1+decay_rate*epoch_num))*a0  
        * a = 0.95^(epoch_num)*a0  
        * a = k/sqrt(epoch_num)*a0  
        * a = k/sqrt(t)*a0(t-mini batch对应的编号)  
        * 离散下降：过一段时间进行一次下降，而不是每一次都下降  
        * 手动调整学习率a  
* 局部最优问题  
    * 局部最优点：各个维度都处于局部最优，<mark>在一般遇到的数据的维度较大的情况下发生概率较小，可以忽略此问题</mark>  
    * 鞍点：只有一个/多个方向为局部最优，其他方向不是，更常遇到这个问题  
        * 平稳段：一块区域，导数长时间较小，接近0，会导致速度很慢，经过很长时间才能够作出平稳段区域，通过Adam等加速算法能够进行改进  
* Batch norm  
    * 如何进行batch norm  
        * 在每一个mini-batch训练时，每一层计算激活值前进行batch norm，针对相应mini-batch的对象计算均值和方差  
            * ![batch-norm](./img/batch-norm.png)
        * 由于可能需要其他的分布，所以进行简单变换（比如sigmoid函数中不希望输入值只分布在01之间）  
            * ![change](./img/change.png)
            * 对于每一层的两个参数选择可以不同，但是不同mini-batch的相同层参数需要相同  
    * 细节  
        * 由于减去了均值，所以b没有了意义，可以省略或设置为0  
        * <mark>测试集的batch norm：</mark>  
            * 不是用本身的均值和方差来计算  
            * 用之前mini-batch记录的方差和均值的加权平均来计算  
            * <mark>why?为了减小计算量？</mark>  
    * 作用  
        * * 统一分布，使得每层之间相互独立，受到前层的影响更小，更稳定  
            * 有正则化效果，防止权重对于某个输入的过于依赖  
