## 卷积神经网络

#### 卷积神经网络

##### 卷积层

###### 过滤器

* f-size：

  * 通常为奇数
    * 方便对称填充
    * 有中心像素点，方便指出过滤器的位置

* 意义和理解

  * 使用不同filter检测方向的边缘

    * 水平边缘

      ![水平边缘](.\水平边缘.png)

    * 竖直边缘

      ![竖直边缘](.\竖直边缘.png)

* 不同边缘

  * 边缘两边明暗的不同对检测结果的影响（filter进行对称变换也会产生相同作用）

    * 暗-亮-暗

      ![filter1](.\filter1.png)

    * 亮-暗-亮

      <img src=".\filter2.png" alt="filter2" style="zoom: 67%;" />

  * filter计算后取绝对值-不关注边界两边的明暗的不同

* 不同filter

  * Sobel过滤器

    * 特点：增加了中间一行的权重

      如
      $$
      \begin{bmatrix}
        1&0&-1\\
        2&0&-2\\
        1&0&-1
      \end{bmatrix}
      $$

    * 效果：结果鲁棒性更好

  * Scharr过滤器：略

  * 学习filter权重：

    * 将权重设置为参数，使神经网络来自动学习他们，通过学习权重来得到检测各种边缘的权重值。

    * 如
      $$
      \begin{bmatrix}
        w_1&w_2&w_3\\
        w_4&w_5&w_6\\
        w_7&w_8&w_9
      \end{bmatrix}
      $$

  * 三维filter：

    * 根据需要设置不同channel的权重大小

    * 如：为了检测红色通道的垂直边缘，filter设置

      channel<sub>1</sub>：
      $$
      \begin{bmatrix}
        1&0&-1\\
        1&0&-1\\
        1&0&-1
      \end{bmatrix}
      $$
      

      channel<sub>2</sub>和channel<sub>3</sub>全部设置为0



###### Padding

* 方法
  * Same：使用padding并且保持卷积后H、W与卷积前一致
  * Valid：不使用padding
* 使用原因
  * 只是简单用filter进行卷积会出现以下问题
    * 每次padding之后图像会缩小
    * 丢失了图像边缘位置的信息



###### stride

* 商不是整数的情况：
  * 向下取整
  * 你只在蓝框完全包括在图像或填充完的图像内部时，才对它进行运算。如果有任意一个蓝框移动到了外面，那你就不要进行相乘操作



###### 卷积层整体

* 多个filter：
  * 方便同时检测不同的内容：如不同角度的边缘
* 计算整体步骤：
  * 非线性激活函数(对应field*filter+偏差) 
  * 偏差b：每一个filter对应一个值
* 表示
  * f<sup>[l]</sup>：第l层的filter大小
  * p<sup>[l]</sup>：第l层的padding的数量/valid/same
  * s<sup>[l]</sup>：第l层的stride
  * 输入：n/h<sup>[l-1]</sup>&times;n/w<sup>[l-1]</sup>&times;n<sub>c</sub><sup>[l-1]</sup>     &rarr; 输出：n/h<sup>[l]</sup>&times;n/w<sup>[l]</sup>&times;n<sub>c</sub><sup>[l]</sup>
* 特点（相对于全连接）
  * 参数少
  * 参数共享
  * 稀疏连接每个输出只和对应的field连接
* 优点
  * 防止过拟合
  * 善于捕捉平移不变



##### 池化层pooling

* 作用：
  * 缩减模型大小
  * 提高计算速度
  * 提高所提取特征的鲁棒性
* 类型：
  * 最大值：常用
  * 平均值：少用
* 理解：
  * 提取主要特征：如maxpool，看每个区域是否检测到了某个特征，如眼睛或边缘，如果检测到了就会有较大的值，maxpool会将这个值提取出
* 有时候间隔池化层作为一个单独的层，有时候conv+pooling整体作为一层



#### 深度卷积神经网络

##### 经典网络

###### LeNet-5

* 构造

  ![LeNet-5](.\LeNet-5.png)

  池化层后面使用了sigmoid函数

* 特点

  * 没有用padding
  * 总是用valid卷积
  * 参数数量：约6万个

* 论文阅读建议

  * 精度第二段，泛读第三段

###### AlexNet

* 构造

  ![AlexNet](.\AlexNet.png)

* 特点

  * AlexNet能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，这一点AlexNet表现出色。
  * 相对LeNet表现更加出色  &larr;  使用了ReLu激活函数

* 论文

  * 使用两个GPU训练

  * *局部响应归一化层（Local Response Normalization/LRN）*：

    * 基本思路

      假如这是网络的一块，比如是13×13×256，LRN要做的就是选取一个位置，比如说这样一个位置，从这个位置穿过整个通道，能得到256个数字，并进行归一化。

    * 动机：对于这张13×13的图像中的每个位置来说，我们可能并不需要太多的高激活神经元。

    * 不常用

###### VGG-16

* 构造

  ![VGG-16](.\VGG-16.png)

* 特点

  * 16：在这个网络中包含16个卷积层和全连接层
  * 卷积层filter数量变化存在一定的规律：64&rarr;128&rarr;256&rarr;512
  * 每次池化后图像大小(H and W)减半，层数翻倍
  * 需要训练的特征数量巨大：包含约1.38亿个参数

* VGG-19

  * 比VGG-16更大
  * 效果差不多



##### ResNets

* 由 *残差块(Residual block)* 构成

  * ![residual block](./Residual block.png)
  * a<sup>[l+2]</sup>=g(z<sup>[l+2]</sup>+a<sup>[l]</sup>)
  * *跳跃连接* ：a<sup>[l]</sup>跳过一层/多层，从而将信息传递到神经网络的更深层

* 整体构造

  * ![Residual Network](./Residual Network.png)

    每两层增加亿个捷径，构成一个残差块；5个残差块连在一起构成一个残差网络。

  * ![ResNets](./ResNet.png)

  * 常用结构：(卷积层-卷积层-卷积层-池化层) &times; n - softmax全连接层进行预测

  * <font color='red'>细节：</font>由于使用了残差，需要保持维度一致 &rarr;使用了很多的same卷积

* 优点：

  * 用普通网络（没有残差），随着神经网络的加深，效果会先变好再变差；

    而使用残差，网络越深效果越好

    ![performance](./ResNet Performance.png)

* 理解
  
  * <font color='red'>恒等式函数？？？</font>



##### 1 &times; 1 卷积/Network in Network

* 理解
  * 对同一个位置上所有channel的值进行全连接
* 意义
  * 压缩通道数量（对比池化：压缩H和W）
  * 增加非线性函数，使得网络可以学习更复杂的函数，但保持通道数量不变
  * 通道数量增加



##### Inception

* 意义

  * 代替决定某层要使用的操作（如filter选择3/5）

  * 不用人为决定是否需要池化或者使用哪种过滤器，而是由网络自行确定这些参数，给网络添加这些参数所有的可能，输出连接起来，让网络自己学习需要什么样的参数/过滤器的组合

    ![inception network](./inception network.png)

* 缺点与改进

  * 计算成本极高

  * 使用*瓶颈层*

    ![瓶颈层](./瓶颈层.png)

    使用 1&times;1 卷积来压缩，然后放大（当合理构建时时，不会有多少的信息损失<font color='red'>why???</font>）

  * 改进后

    ![improved inception network](./improved inception network.png)

    maxpool后使用1&times;1网络是为了压缩对应通道数，避免maxpool占用通道过多（maxpool不改变channel数量）

* 整体构造

  ![inception](./inception.png)

  中间和隐藏层也能预测图片，起到调整作用，防止过拟合



##### 开源和迁移学习

* Github中寻找开源的有关网络代码

  * ResNets：[*https://github.com/KaimingHe/deep-residual-networks*](https://github.com/KaimingHe/deep-residual-networks)

* 迁移学习

  * Github上下载有关已经训练好的模型，借用训练自己的模型

  * 根据现有训练数据的数量确定训练方式：

    如

    * 当数据量很少时，只训练最后softmax的参数，前面参数固定
    * 当数据量多一些时，训练的部分可以向前拓展，使得更多参数进行训练

  * 训练技巧：先使得要训练的数据计算经过固定的部分，记录得到的数据，然后只看后面部分进行训练

  * 常用参数：trainableParameter=0 / freeze=1



##### 数据增强

* 常用方法：
  * 裁剪：可能会得到难以辨别的图片
  * 镜像对称
  * 旋转
  * 扭曲变形
  * 色彩变换：
    * 给R、G、B三个通道加上不同程度的失真值  &rarr;  鲁棒性更好
    * PCA主成分分析
* 数据增强中的超参数
  * <font color='red'>裁剪的参数，色彩变换的参数等等都是超参数，要调整</font>



##### 计算机视觉现状

* 集成学习

  * 同时独立用多个不同网络训练，平均输出

* multi-crop

  * 将裁剪运用到测试集中

  * 如：10-crop

    ![10-crop](./10-crop.png)

    这是这里（编号1）和这里（编号3）就是中心crop，这里（编号2）和这里（编号4）就是四个角落的crop。如果把这些加起来，就会有10种不同的图像的crop，因此命名为10-crop。所以你要做的就是，通过你的分类器来运行这十张图片，然后对结果进行平均




#### 目标检测

##### 目标定位

* 内容

  * 定位分类问题
  * 判断图片是否含某个对象+在图片中标记出对象的位置

* 目标标签：

  * $$
    y=\begin{bmatrix}
      p_c\\b_x\\b_y\\b_h\\b_w\\c_1\\c_2\\c_3\\
    \end{bmatrix}
    $$

  * p<sub>c</sub>：包含对象为1，否则为0

    b<sub>x</sub>+b<sub>y</sub>：对象框中心点的位置（相对于图片而言，在[0,1]内）

    b<sub>h</sub>+b<sub>w</sub>：对象框的长和宽（相对于图片而言，在[0,1]内）

    c<sub>1</sub>+c<sub>2</sub>+c<sub>3</sub>：属于哪一类对象，对应的下标就为1，其他为0

  * 如果p<sub>c</sub>为0，后面的都不重要了，可以用？表示

* 损失函数

  * 对于p<sub>c</sub>为1时，损失函数是向量后面项的平方和
  * 对于p<sub>c</sub>为0时，损失函数只考虑p<sub>c</sub>，差的平方
  * 

##### 特征点检测

* 应用
  * 检测面部笑脸：通过眼睛上的某些特征点（如：内/外眼角）或嘴上的特征点（如嘴角位置的变化）检测
  * 运动分析：对于人的身躯，找出某几个特征点，来分析人的运动





#### 特殊应用

